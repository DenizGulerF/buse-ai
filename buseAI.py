# -*- coding: utf-8 -*-
"""BuseAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14CMOHlw3mNijZql0jhsSieMNKYARmnJt
"""

import pandas as pd

try:
    df = pd.read_csv('Reviews.csv', sep='\t', names=['review'])
    display(df.head())
except FileNotFoundError:
    print("Error: 'Reviews.csv' not found.")
    df = pd.DataFrame() # Create an empty DataFrame to avoid errors later
except pd.errors.ParserError:
    print("Error: Could not parse the file. Check the file format.")
    df = pd.DataFrame() # Create an empty DataFrame to avoid errors later
except Exception as e:
    print(f"An unexpected error occurred: {e}")
    df = pd.DataFrame() # Create an empty DataFrame to avoid errors later


if not df.empty:
    df = df.iloc[1:]  # Remove the header row
    display(df.head())
else:
    print("DataFrame is empty. Cannot remove header row.")

"""# Removing Emojis, Signs and Stopwords & Converting Lowercase & Lemmatisation"""

import re
import pandas as pd
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer


# Download NLTK resources
try:
    nltk.data.find('corpora/stopwords')
    nltk.data.find('tokenizers/punkt')
    nltk.data.find('corpora/wordnet')
    nltk.data.find('omw-1.4')
except LookupError:
    nltk.download('stopwords')
    nltk.download('punkt')
    nltk.download('punkt_tab')
    nltk.download('wordnet')
    nltk.download('omw-1.4')

# Create custom stopwords list for sentiment analysis
stop_words = set(stopwords.words('english'))
sentiment_important_words = {'no', 'not', 'very', 'but', 'never', 'none', 'nobody', 'nowhere', 'against', "n't"}
custom_stopwords = stop_words - sentiment_important_words

# Initialize lemmatizer
lemmatizer = WordNetLemmatizer()

# Define all cleaning functions
def remove_html_tags(text):
    if isinstance(text, str):
        clean = re.compile('<.*?>')
        return re.sub(clean, '', text)
    return text

def remove_punctuation(text):
    if isinstance(text, str):
        # Keep apostrophes for contractions
        text = re.sub(r"'", "'", text)
        text = re.sub(r'[^\w\s\']', '', text)
        return text
    return text

def remove_emoji(text):
    if isinstance(text, str):
        emoji_pattern = re.compile("["
                           u"\U0001F600-\U0001F64F"
                           u"\U0001F300-\U0001F5FF"
                           u"\U0001F680-\U0001F6FF"
                           u"\U0001F1E0-\U0001F1FF"
                           u"\U00002702-\U000027B0"
                           u"\U000024C2-\U0001F251"
                           "]+", flags=re.UNICODE)
        return emoji_pattern.sub(r'', text)
    return text

def custom_stopwords_removal(text):
    if isinstance(text, str):
        word_tokens = word_tokenize(text)
        filtered_sentence = [w for w in word_tokens if not w.lower() in custom_stopwords]
        return " ".join(filtered_sentence)
    return text

def lemmatize_text(text):
    if isinstance(text, str):
        word_tokens = word_tokenize(text)
        lemmas = [lemmatizer.lemmatize(word) for word in word_tokens]
        return " ".join(lemmas)
    return text

def handle_negations(text):
    if not isinstance(text, str):
        return text

    negations = {'not', 'no', 'never', "n't", 'cannot', 'wasnt', 'isnt', 'arent',
                 'wont', 'wouldnt', 'shouldnt', 'couldnt', 'dont', 'doesnt'}
    words = text.split()
    modified_words = []
    neg_flag = False

    for i, word in enumerate(words):
        if word.lower() in negations:
            neg_flag = True
            modified_words.append(word)
            continue

        if neg_flag and i < len(words)-1:
            modified_words.append(word + '_NEG')
        else:
            modified_words.append(word)

        if len(modified_words) - len([w for w in modified_words if '_NEG' in w]) >= 3:
            neg_flag = False

    return ' '.join(modified_words)

try:
    # Load the dataset
    df = pd.read_csv('Reviews.csv')
    print(f"Loaded CSV file with shape: {df.shape}")
    print("Available columns:", df.columns.tolist())

    # Identify text column
    text_column = None
    possible_columns = ['review', 'Review', 'text', 'Text', 'comment', 'Comment',
                       'description', 'Description', 'reviewText', 'summary']

    for col in possible_columns:
        if col in df.columns:
            text_column = col
            break

    if text_column is None:
        for col in df.columns:
            if df[col].dtype == 'object':
                sample = df[col].dropna().head(3).astype(str)
                if any(len(text) > 50 for text in sample):
                    text_column = col
                    break

    # Process the text
    if text_column:
        print(f"Using '{text_column}' for text cleaning")

        # Convert to lowercase
        df['lowercase_text'] = df[text_column].str.lower()

        # Apply cleaning functions in sequence
        print("Applying text cleaning...")
        df['cleaned_text'] = df['lowercase_text'].apply(remove_html_tags)
        df['cleaned_text'] = df['cleaned_text'].apply(remove_punctuation)
        df['cleaned_text'] = df['cleaned_text'].apply(remove_emoji)

        # Remove custom stopwords
        print("Removing stopwords while keeping sentiment-important words...")
        df['filtered_text'] = df['cleaned_text'].apply(custom_stopwords_removal)

        # Apply lemmatization
        print("Applying lemmatization...")
        df['lemmatized_text'] = df['filtered_text'].apply(lemmatize_text)

        # Handle negations
        print("Handling negations...")
        df['processed_text'] = df['lemmatized_text'].apply(handle_negations)

        # Display results
        print("\nSample of processed texts:")
        display(df[['lowercase_text', 'processed_text']].head())

    else:
        print("Could not identify a suitable text column.")
        print("Please specify the column containing review text manually.")
        print("Available columns:", df.columns.tolist())

except FileNotFoundError:
    print("Error: 'Reviews.csv' file not found in the current directory.")
except Exception as e:
    print(f"An error occurred: {str(e)}")

"""# Word Frequency Analysis"""

# Ensure required packages are installed
#%pip install matplotlib seaborn

import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter

# Define words to exclude from frequency analysis
exclude_words = {'no', 'not', 'very', 'but', 'never', 'none', 'nobody',"make","much",
                'nowhere', 'against', "n't", 'cant', 'wont', 'dont',"get", "want",
                'doesnt', 'isnt', 'wasnt', 'shouldnt', 'couldnt', 'wouldnt', "'s","would","one"}

# Create two separate analyses: one for regular words and one for negated words
regular_words = []
negated_words = []

for text in df['processed_text']:
    if isinstance(text, str):
        words = text.split()
        for word in words:
            # Check for negated words
            if '_NEG' in word:
                word_clean = word.replace('_NEG', '')
                if word_clean.lower() not in exclude_words:
                    negated_words.append(word_clean)
            # Add regular words only if they're not in exclude_words
            elif word.lower() not in exclude_words:
                regular_words.append(word)

# Count frequencies
regular_word_counts = Counter(regular_words)
negated_word_counts = Counter(negated_words)

# Get top 15 words for each category
top_regular = regular_word_counts.most_common(15)
top_negated = negated_word_counts.most_common(15)

# Create subplots
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))

# Plot regular words
words_reg, counts_reg = zip(*top_regular)
sns.barplot(x=list(counts_reg), y=list(words_reg), ax=ax1, palette='viridis')
ax1.set_title('Top 15 Most Common Words')
ax1.set_xlabel('Frequency')

# Plot negated words
if negated_words:  # Only plot if there are negated words
    words_neg, counts_neg = zip(*top_negated)
    sns.barplot(x=list(counts_neg), y=list(words_neg), ax=ax2, palette='rocket')
    ax2.set_title('Top 15 Most Common Negated Words')
    ax2.set_xlabel('Frequency')

plt.tight_layout()
plt.show()

# Print some statistics
print("\nWord Frequency Statistics:")
print(f"Total unique words: {len(regular_word_counts)}")
print(f"Total unique negated words: {len(negated_word_counts)}")
print("\nTop 5 regular words:")
for word, count in top_regular[:5]:
    print(f"{word}: {count}")
print("\nTop 5 negated words:")
for word, count in top_negated[:5]:
    print(f"{word}: {count}")


# Ensure scikit-learn is installed
# %pip install scikit-learn

from sklearn.feature_extraction.text import TfidfVectorizer


# Create TF-IDF Vectorizer with optimized parameters for sentiment analysis
vectorizer = TfidfVectorizer(
    max_features=5000,
    min_df=20,              # Ignore terms that appear in less than 20 documents
    max_df=0.95,            # Ignore terms that appear in more than 95% of documents
    ngram_range=(1, 2),     # Include both unigrams and bigrams
    sublinear_tf=True       # Apply sublinear scaling to term frequencies
)

# Transform the processed text
X = vectorizer.fit_transform(df['processed_text'])

# Get feature names and their IDF scores
feature_names = vectorizer.get_feature_names_out()
idf_values = vectorizer.idf_

# Create a DataFrame of features and their IDF scores
feature_importance = pd.DataFrame({
    'feature': feature_names,
    'importance': idf_values
})

# Sort by importance
feature_importance = feature_importance.sort_values('importance', ascending=False)

# Visualize top features
plt.figure(figsize=(12, 6))
sns.barplot(data=feature_importance.head(15), x='importance', y='feature', palette='viridis')
plt.title('Top 15 Most Important Features by TF-IDF Score')
plt.xlabel('IDF Score')
plt.tight_layout()
plt.show()

# Print some statistics
print("\nTF-IDF Statistics:")
print(f"Total number of features: {len(feature_names)}")
print(f"Matrix shape: {X.shape}")
print("\nTop 10 most important features:")
for _, row in feature_importance.head(10).iterrows():
    print(f"{row['feature']}: {row['importance']:.4f}")

# Get vocabulary size
vocab_size = len(vectorizer.vocabulary_)
print(f"\nVocabulary size: {vocab_size}")

"""# Train-Test"""

from sklearn.model_selection import train_test_split

# First check class distribution
print("Original Score Distribution:")
print(df['Score'].value_counts(normalize=True).sort_index())

# First split: separate test set (80% train+val, 20% test)
X_temp, X_test, y_temp, y_test = train_test_split(
    X,
    df['Score'],
    test_size=0.2,
    random_state=42,
    stratify=df['Score']  # Maintain class distribution
)

# Second split: separate validation set from training (80% train, 20% val of remaining data)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp,
    y_temp,
    test_size=0.2,
    random_state=42,
    stratify=y_temp
)

# Print dataset sizes and distributions
print("\nDataset Sizes:")
print(f"Training set: {X_train.shape[0]} samples")
print(f"Validation set: {X_val.shape[0]} samples")
print(f"Test set: {X_test.shape[0]} samples")

print("\nClass Distribution in Each Split:")
print("\nTraining Set Distribution:")
print(y_train.value_counts(normalize=True).sort_index())
print("\nValidation Set Distribution:")
print(y_val.value_counts(normalize=True).sort_index())
print("\nTest Set Distribution:")
print(y_test.value_counts(normalize=True).sort_index())

"""# Model Selection"""

from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder

# Create label encoder
le = LabelEncoder()

# Transform labels to start from 0
y_train_encoded = le.fit_transform(y_train)
y_val_encoded = le.transform(y_val)
y_test_encoded = le.transform(y_test)

# Dictionary of models with optimized parameters
models = {
    'Logistic Regression': LogisticRegression(
        max_iter=2000,
        class_weight='balanced',
        n_jobs=-1
    ),
    'Linear SVM': LinearSVC(
        dual=False,
        class_weight='balanced',
        max_iter=2000,
        random_state=42
    ),
    'Random Forest': RandomForestClassifier(
        n_estimators=200,  # Increased to 200
        class_weight='balanced',
        n_jobs=-1,
        random_state=42
    ),
    'XGBoost': XGBClassifier(
        use_label_encoder=False,
        eval_metric='logloss',
        random_state=42,
        n_jobs=-1
    )
}

# Train and evaluate each model
results = {}
for name, model in models.items():
    print(f"\nTraining {name}...")

    # Train the model with timing
    from time import time
    start_time = time()

    # Train the model
    if name == 'XGBoost':
        model.fit(X_train, y_train_encoded,
                 eval_set=[(X_val, y_val_encoded)],
                 verbose=0)
    else:
        # For other models, use encoded labels too
        model.fit(X_train, y_train_encoded)

    training_time = time() - start_time

    # Make predictions and convert back to original labels
    val_pred = model.predict(X_val)
    if name == 'XGBoost':
        val_pred = le.inverse_transform(val_pred)
        y_val_compare = y_val
    else:
        val_pred = le.inverse_transform(val_pred)
        y_val_compare = y_val

    # Calculate accuracy
    val_accuracy = accuracy_score(y_val_compare, val_pred)

    # Store results
    results[name] = {
        'model': model,
        'val_accuracy': val_accuracy,
        'training_time': training_time,
        'report': classification_report(y_val_compare, val_pred)
    }

    print(f"\n{name} Results:")
    print(f"Training Time: {training_time:.2f} seconds")
    print(f"Validation Accuracy: {val_accuracy:.4f}")
    print("\nDetailed Classification Report:")
    print(results[name]['report'])

# Find best model
best_model_name = max(results.items(), key=lambda x: x[1]['val_accuracy'])[0]
print(f"\nBest performing model: {best_model_name}")
print(f"Best validation accuracy: {results[best_model_name]['val_accuracy']:.4f}")
print(f"Training time: {results[best_model_name]['training_time']:.2f} seconds")

"""# Ensemble Methods"""

from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import VotingClassifier
from sklearn.svm import LinearSVC
from sklearn.linear_model import LogisticRegression

# Scale the features
scaler = StandardScaler(with_mean=False)  # with_mean=False because we have sparse matrix
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Create ensemble of different classifiers with adjusted parameters
ensemble = VotingClassifier(
    estimators=[
        ('nb', MultinomialNB()),
        ('svc', LinearSVC(max_iter=5000)),
        ('lr', LogisticRegression(max_iter=3000, solver='lbfgs'))
    ],
    voting='hard'
)

# Fit and predict
ensemble.fit(X_train_scaled, y_train)
y_pred = ensemble.predict(X_test_scaled)
print("Ensemble accuracy:", accuracy_score(y_test, y_pred))

from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import StandardScaler, MaxAbsScaler
from sklearn.ensemble import VotingClassifier
from sklearn.svm import LinearSVC
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import SelectFromModel
from sklearn.pipeline import Pipeline

# Use a less strict threshold for feature selection
importance_threshold = feature_importance['importance'].quantile(0.5)  # Select top 50% features

# Create feature selector with custom threshold
feature_selector = SelectFromModel(
    estimator=LogisticRegression(max_iter=3000),
    threshold=importance_threshold,
    prefit=False
)

# Create enhanced ensemble pipeline
enhanced_pipeline = Pipeline([
    ('scaler', MaxAbsScaler()),  # Better for sparse matrices than StandardScaler
    ('feature_selection', feature_selector),
    ('ensemble', VotingClassifier(
        estimators=[
            ('nb', MultinomialNB(alpha=0.1)),
            ('svc', LinearSVC(
                max_iter=5000,
                C=1.0,
                class_weight='balanced'
            )),
            ('lr', LogisticRegression(
                max_iter=3000,
                solver='saga',
                C=1.0,
                class_weight='balanced'
            ))
        ],
        voting='hard',
        weights=[2, 1, 1]
    ))
])

# Fit and predict without intermediate scaling
enhanced_pipeline.fit(X_train, y_train)
y_pred = enhanced_pipeline.predict(X_test)

# Print results
print("Enhanced Ensemble accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Get selected features
selected_features_mask = enhanced_pipeline.named_steps['feature_selection'].get_support()
selected_features = feature_names[selected_features_mask]
print(f"\nNumber of selected features: {len(selected_features)}")
print("\nTop 10 selected features:")
print(selected_features[:10])

"""# Advanced Stacking Ensemble"""

"""
Advanced Stacking Ensemble for Sentiment Analysis
This implementation uses meta-learning, advanced feature engineering,
and hyperparameter-tuned models to improve accuracy.
"""

import numpy as np
from sklearn.preprocessing import MaxAbsScaler
from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import cross_val_predict
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, classification_report
from xgboost import XGBClassifier
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from scipy.sparse import hstack, csr_matrix
import pandas as pd

# 1. Feature Engineering: Extract additional features

def extract_additional_features(X_data, processed_texts):
    """Extract text-based features to complement TF-IDF vectors"""

    # Initialize empty arrays for new features
    text_lengths = []
    word_counts = []
    avg_word_length = []
    negation_counts = []

    # Process each text entry
    for text in processed_texts:
        if isinstance(text, str):
            # Text length
            text_lengths.append(len(text))

            # Word count
            words = text.split()
            word_counts.append(len(words))

            # Average word length
            if words:
                avg_word_length.append(sum(len(word) for word in words) / len(words))
            else:
                avg_word_length.append(0)

            # Negation count
            negation_counts.append(sum(1 for word in words if '_NEG' in word))
        else:
            # Handle non-string entries
            text_lengths.append(0)
            word_counts.append(0)
            avg_word_length.append(0)
            negation_counts.append(0)

    # Create a DataFrame of engineered features
    feature_df = pd.DataFrame({
        'text_length': text_lengths,
        'word_count': word_counts,
        'avg_word_length': avg_word_length,
        'negation_count': negation_counts
    })

    # Scale numeric features and convert to sparse for compatibility with TF-IDF
    scaler = MaxAbsScaler()
    scaled_features = scaler.fit_transform(feature_df)
    sparse_features = csr_matrix(scaled_features)

    # Combine with TF-IDF features
    combined_features = hstack([X_data, sparse_features])

    return combined_features

# 2. Create a stacking ensemble with meta-learning

def create_stacking_ensemble(X_train, y_train, X_val, y_val, feature_names):
    """
    Creates a stacking ensemble with multiple base models and a meta-learner
    """

    # Base models with optimized hyperparameters
    base_models = {
        'naive_bayes': MultinomialNB(alpha=0.1),
        'logistic_regression': LogisticRegression(
            C=2.0,
            solver='saga',
            penalty='l1',
            max_iter=5000,
            class_weight='balanced',
            n_jobs=-1,
            random_state=42
        ),
        'linear_svc': LinearSVC(
            C=1.0,
            loss='squared_hinge',
            penalty='l2',
            dual=False,
            max_iter=10000,
            class_weight='balanced',
            random_state=42
        ),
        'random_forest': RandomForestClassifier(
            n_estimators=300,
            max_depth=20,
            min_samples_split=5,
            min_samples_leaf=2,
            max_features='sqrt',
            bootstrap=True,
            class_weight='balanced',
            n_jobs=-1,
            random_state=42
        ),
        'gradient_boosting': GradientBoostingClassifier(
            n_estimators=200,
            learning_rate=0.05,
            max_depth=5,
            min_samples_split=10,
            min_samples_leaf=4,
            subsample=0.8,
            random_state=42
        ),
        'xgboost': XGBClassifier(
            n_estimators=300,
            learning_rate=0.05,
            max_depth=6,
            min_child_weight=2,
            gamma=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            scale_pos_weight=1,
            reg_alpha=0.01,
            reg_lambda=1,
            use_label_encoder=False,
            eval_metric='logloss',
            n_jobs=-1,
            random_state=42
        )
    }

    # Train base models and generate meta-features
    meta_features_train = np.zeros((X_train.shape[0], len(base_models)))
    meta_features_val = np.zeros((X_val.shape[0], len(base_models)))

    print("\nTraining base models for stacking...")

    for i, (name, model) in enumerate(base_models.items()):
        print(f"Training {name}...")

        # For XGBoost, we need to handle the sparse matrix differently
        if name == 'xgboost':
            # Convert to dense for XGBoost
            if hasattr(X_train, 'toarray'):
                x_train_dense = X_train.toarray()
                x_val_dense = X_val.toarray()
                model.fit(x_train_dense, y_train)
                meta_features_train[:, i] = model.predict_proba(x_train_dense)[:, 1]
                meta_features_val[:, i] = model.predict_proba(x_val_dense)[:, 1]
            else:
                model.fit(X_train, y_train)
                meta_features_train[:, i] = model.predict_proba(X_train)[:, 1]
                meta_features_val[:, i] = model.predict_proba(X_val)[:, 1]
        else:
            # Use cross-validation to avoid overfitting
            if hasattr(model, 'predict_proba'):
                meta_features_train[:, i] = cross_val_predict(
                    model, X_train, y_train, cv=5, method='predict_proba'
                )[:, 1]

                model.fit(X_train, y_train)
                meta_features_val[:, i] = model.predict_proba(X_val)[:, 1]
            else:
                # For models without predict_proba
                model.fit(X_train, y_train)
                meta_features_train[:, i] = cross_val_predict(
                    model, X_train, y_train, cv=5, method='decision_function'
                )
                meta_features_val[:, i] = model.decision_function(X_val)

    # Meta learner: LogisticRegression with optimized hyperparameters
    meta_learner = LogisticRegression(
        C=3.0,
        solver='liblinear',
        max_iter=2000,
        class_weight='balanced',
        random_state=42
    )

    print("Training meta-learner...")
    meta_learner.fit(meta_features_train, y_train)

    # Evaluate meta-learner on validation set
    val_predictions = meta_learner.predict(meta_features_val)
    val_accuracy = accuracy_score(y_val, val_predictions)

    print(f"\nStacking ensemble validation accuracy: {val_accuracy:.4f}")
    print("\nClassification Report (Validation):")
    print(classification_report(y_val, val_predictions))

    return base_models, meta_learner, val_accuracy

# 3. Final prediction function for test data

def predict_with_stacking_ensemble(base_models, meta_learner, X_test):
    """Generate predictions using the stacking ensemble"""

    # Generate meta-features for test data
    meta_features_test = np.zeros((X_test.shape[0], len(base_models)))

    for i, (name, model) in enumerate(base_models.items()):
        # For XGBoost, handle sparse matrix differently
        if name == 'xgboost':
            if hasattr(X_test, 'toarray'):
                meta_features_test[:, i] = model.predict_proba(X_test.toarray())[:, 1]
            else:
                meta_features_test[:, i] = model.predict_proba(X_test)[:, 1]
        else:
            if hasattr(model, 'predict_proba'):
                meta_features_test[:, i] = model.predict_proba(X_test)[:, 1]
            else:
                meta_features_test[:, i] = model.decision_function(X_test)

    # Make final predictions
    test_predictions = meta_learner.predict(meta_features_test)

    return test_predictions

# 4. Main execution function

def improved_sentiment_analysis(X_train, y_train, X_test, y_test, X_val, y_val, processed_texts_train, processed_texts_test, processed_texts_val, feature_names):
    """
    Main function to execute the improved sentiment analysis pipeline
    """

    print("Enhancing features with text metadata...")
    X_train_enhanced = extract_additional_features(X_train, processed_texts_train)
    X_val_enhanced = extract_additional_features(X_val, processed_texts_val)
    X_test_enhanced = extract_additional_features(X_test, processed_texts_test)

    print(f"Original feature shape: {X_train.shape}")
    print(f"Enhanced feature shape: {X_train_enhanced.shape}")

    # Create and train the stacking ensemble
    base_models, meta_learner, val_accuracy = create_stacking_ensemble(
        X_train_enhanced, y_train, X_val_enhanced, y_val, feature_names
    )

    # Make predictions on the test set
    test_predictions = predict_with_stacking_ensemble(
        base_models, meta_learner, X_test_enhanced
    )

    # Evaluate performance on test set
    test_accuracy = accuracy_score(y_test, test_predictions)

    print("\n----- Final Test Results -----")
    print(f"Test accuracy: {test_accuracy:.4f}")
    print("\nClassification Report (Test):")
    print(classification_report(y_test, test_predictions))

    return test_accuracy, base_models, meta_learner

processed_texts_train = df.loc[y_train.index, 'processed_text']
processed_texts_val = df.loc[y_val.index, 'processed_text']
processed_texts_test = df.loc[y_test.index, 'processed_text']

test_accuracy, base_models, meta_learner = improved_sentiment_analysis(
    X_train, y_train, X_test, y_test, X_val, y_val,
    processed_texts_train, processed_texts_test, processed_texts_val,
    feature_names
)

"""# Implementation"""

# Import the improved_sentiment_analysis function
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
from scipy.sparse import hstack, csr_matrix
from sklearn.preprocessing import MaxAbsScaler
from sklearn.feature_extraction.text import TfidfVectorizer
import matplotlib.pyplot as plt
import seaborn as sns

# 1. First, make sure we have the processed text data aligned with indices
print("Preparing data for enhanced model...")

# Create arrays for the processed texts
processed_texts_train = df.iloc[y_train.index]['processed_text'].values if hasattr(y_train, 'index') else df['processed_text'].values[y_train.index]
processed_texts_val = df.iloc[y_val.index]['processed_text'].values if hasattr(y_val, 'index') else df['processed_text'].values[y_val.index]
processed_texts_test = df.iloc[y_test.index]['processed_text'].values if hasattr(y_test, 'index') else df['processed_text'].values[y_test.index]

# 2. Try an improved TF-IDF vectorizer with better parameters
print("Creating optimized TF-IDF features...")

# Improved TF-IDF vectorizer
optimized_vectorizer = TfidfVectorizer(
    max_features=10000,    # Increase max features
    min_df=10,             # Lower document frequency threshold
    max_df=0.9,
    ngram_range=(1, 3),    # Include unigrams, bigrams and trigrams
    sublinear_tf=True,
    use_idf=True,
    norm='l2'
)

# Re-extract text features with improved vectorizer
X_train_new = optimized_vectorizer.fit_transform(processed_texts_train)
X_val_new = optimized_vectorizer.transform(processed_texts_val)
X_test_new = optimized_vectorizer.transform(processed_texts_test)

feature_names_new = optimized_vectorizer.get_feature_names_out()
print(f"New TF-IDF feature shape: {X_train_new.shape}")

# 3. Extract additional features function
def extract_additional_features(texts):
    """Extract text-based features to complement TF-IDF vectors"""

    # Initialize empty arrays for new features
    text_lengths = []
    word_counts = []
    avg_word_length = []
    negation_counts = []
    sentiment_words = []
    question_marks = []
    exclamation_marks = []
    capitalized_words = []
    intensity_scores = []  # New for intensifiers

    # Sentiment lexicon
    positive_words = {
        'accessible', 'advantageous', 'affordable', 'authentic', 'awesome', 'balanced',
        'beautiful', 'best', 'brilliant', 'clean', 'comfy', 'comfortable', 'consistent',
        'convenient', 'cool', 'cute', 'delighted', 'durable', 'efficient', 'enjoyable',
        'exceptional', 'excellent', 'fantastic', 'fast', 'favorite', 'fit', 'flawless',
        'fresh', 'friendly', 'genuine', 'good', 'grateful', 'happy', 'helpful', 'ideal',
        'impressed', 'impressive', 'liked', 'love', 'loved', 'organized', 'outstanding',
        'perfect', 'pleased', 'premium', 'professional', 'prompt', 'pure', 'quality',
        'quick', 'reasonable', 'recommend', 'recommended', 'reliable', 'responsive',
        'same','satisfied', 'seamless', 'smart', 'smooth', 'sturdy', 'tasty',
        'trustworthy','valuable', 'well', 'wonderful', 'worth', 'worthy'
    }

    negative_words = {
        'annoyed', 'annoying', 'avoid', 'bitter', 'broken', 'bug',
        'comfy_NEG', 'comfortable_NEG', 'confused', 'costly', 'cracks', 'cracked',
        'crap', 'crappy', 'damaged', 'defective', 'delayed', 'deteriorated', 'dirty',
        'disappointed', 'disappointment', 'dishonest', 'disgusting', 'dislike',
        'dissatisfied', 'expired', 'failed', 'fake', 'faking', 'faulty', 'flaw',
        'flaws', 'flimsy', 'fraudulent', 'frustrate', 'frustrating', 'good_NEG',
        'greasy', 'gross', 'harmful', 'hate', 'hated', 'hating', 'helpful_NEG',
        'horrible', 'ignored', 'incompetent', 'incomplete',
        'inconsistent', 'inferior', 'inappropriate', 'lag', 'lagged', 'lagging',
        'leaking', 'liar', 'lies', 'lie', 'low', 'malfunctioning', 'misguide',
        'misguided', 'mishandled', 'mislead', 'misleading', 'moldy', 'moth',
        'neglected', 'overpriced', 'poor', 'pricey', 'problem', 'recommend_NEG',
        'respond_NEG','returned', 'ridiculous', 'rot', 'rotten', 'rude', 'same_NEG',
        'scam', 'scammed', 'shit', 'shitty','spoiled', 'stinks', 'stinky', 'stupid',
        'suspicious', 'terrible', 'toxic','slow','uncomfortable', 'uncomfy', 'unhelpful',
        'unreliable','unresponsive','upset', 'useless', 'waste', 'worst', 'wrong'
    }
    # Generate negated positive terms
    negative_words.update({f"{word}_NEG" for word in positive_words})

    # Intensifiers
    intensifiers = {'very', 'really', 'extremely', 'absolutely', 'totally', 'completely','lot','lots','definitelly',
                    'much','many','freaking','overwhelmingly','especially','quite','seriously','truly'}

    # Process each text entry
    for text in texts:
        if isinstance(text, str):
            # Text length
            text_lengths.append(len(text))

            # Word count
            words = text.split()
            word_count = len(words)
            word_counts.append(word_count)

            # Average word length
            if words:
                avg_word_length.append(sum(len(word) for word in words) / word_count)
            else:
                avg_word_length.append(0)

            # Negation count
            neg_count = sum(1 for word in words if '_NEG' in word)
            negation_counts.append(neg_count)

            # Count sentiment words
            pos_count = sum(1 for word in words if word.lower() in positive_words)
            neg_count = sum(1 for word in words if word.lower() in negative_words)
            sentiment_words.append(pos_count - neg_count)  # Sentiment score

            # Punctuation counts
            question_marks.append(text.count('?'))
            exclamation_marks.append(text.count('!'))

            # Capitalized words (might indicate emphasis)
            cap_count = sum(1 for word in words if word.isupper() and len(word) > 1)
            capitalized_words.append(cap_count)

            # Intensifier count - your second addition
            intensity_score = sum(1 for word in words if word.lower() in intensifiers)
            intensity_scores.append(intensity_score)
        else:
            # Handle non-string entries
            text_lengths.append(0)
            word_counts.append(0)
            avg_word_length.append(0)
            negation_counts.append(0)
            sentiment_words.append(0)
            question_marks.append(0)
            exclamation_marks.append(0)
            capitalized_words.append(0)
            intensity_scores.append(0)

    # Create a DataFrame of engineered features
    feature_df = pd.DataFrame({
        'text_length': text_lengths,
        'word_count': word_counts,
        'avg_word_length': avg_word_length,
        'negation_count': negation_counts,
        'sentiment_score': sentiment_words,
        'question_marks': question_marks,
        'exclamation_marks': exclamation_marks,
        'capitalized_words': capitalized_words,
        'intensity_score': intensity_scores
    })

    # Add derived features
    feature_df['words_per_char'] = feature_df['word_count'] / (feature_df['text_length'] + 1)
    feature_df['emotion_punctuation'] = feature_df['exclamation_marks'] + feature_df['question_marks']

    # Your third addition - ratio features
    feature_df['positive_ratio'] = feature_df['sentiment_score'] / (feature_df['word_count'] + 1)
    feature_df['negation_ratio'] = feature_df['negation_count'] / (feature_df['word_count'] + 1)
    feature_df['emphasis_score'] = (feature_df['capitalized_words'] +
                                   feature_df['exclamation_marks']) / (feature_df['word_count'] + 1)

    # Scale numeric features and convert to sparse for compatibility with TF-IDF
    scaler = MaxAbsScaler()
    scaled_features = scaler.fit_transform(feature_df)
    sparse_features = csr_matrix(scaled_features)

    return sparse_features, feature_df.columns.tolist()

# 4. Create enhanced feature sets
print("Extracting additional text features...")
train_meta_features, meta_feature_names = extract_additional_features(processed_texts_train)
val_meta_features, _ = extract_additional_features(processed_texts_val)
test_meta_features, _ = extract_additional_features(processed_texts_test)

# Combine TF-IDF with meta features
X_train_enhanced = hstack([X_train_new, train_meta_features])
X_val_enhanced = hstack([X_val_new, val_meta_features])
X_test_enhanced = hstack([X_test_new, test_meta_features])

print(f"Enhanced training feature shape: {X_train_enhanced.shape}")

# 5. Import the stacking ensemble code
# Note: Run the code from the first artifact first

# 6. Run the improved stacking ensemble
print("\nTraining the stacking ensemble...")
test_accuracy, base_models, meta_learner = improved_sentiment_analysis(
    X_train_enhanced, y_train, X_test_enhanced, y_test, X_val_enhanced, y_val,
    processed_texts_train, processed_texts_test, processed_texts_val,
    list(feature_names_new) + meta_feature_names
)

# 7. Visualize results compared to previous model
print("\nComparing models:")
models = ['Original Ensemble', 'Advanced Stacking Ensemble']
accuracies = [0.7412, test_accuracy]  # Your original accuracy was 74.12%

plt.figure(figsize=(10, 6))
sns.barplot(x=models, y=accuracies)
plt.ylim(0.70, max(accuracies) + 0.05)
plt.title('Model Accuracy Comparison')
plt.ylabel('Accuracy')
plt.axhline(y=0.7412, color='r', linestyle='--', label='Original Model')
plt.tight_layout()
plt.show()

# 8. Analyze feature importance from the stacking ensemble
# For demonstration, we'll show feature importance from one of the base models
if 'random_forest' in base_models:
    # Get feature importance from random forest
    rf_model = base_models['random_forest']
    if hasattr(rf_model, 'feature_importances_'):
        # Get all feature names (TF-IDF + meta features)
        all_feature_names = list(feature_names_new) + meta_feature_names

        # Get top 15 important features
        importances = rf_model.feature_importances_
        indices = np.argsort(importances)[::-1][:15]

        plt.figure(figsize=(12, 8))
        sns.barplot(x=importances[indices], y=[all_feature_names[i] for i in indices])
        plt.title('Top 15 Most Important Features')
        plt.tight_layout()
        plt.show()

print("\nModel improvement complete!")

"""# GPU optimised dependencies"""

# Run this installation cell first to set up GPU dependencies
!pip install --upgrade xgboost>=1.6.0
!pip install cupy-cuda11x
!pip install cudf-cu11 cuml-cu11
!pip install torch

# Verify GPU access and library installation
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA device: {torch.cuda.get_device_name(0)}")

# Import required libraries for the main script
import numpy as np
import pandas as pd
import xgboost as xgb
try:
    import cupy as cp
    print("CuPy successfully imported")
except:
    print("CuPy import failed - will use CPU fallback")
try:
    import cudf
    print("cuDF successfully imported")
except:
    print("cuDF import failed - will use CPU fallback")
try:
    from cuml.svm import LinearSVC
    print("cuML successfully imported")
except:
    print("cuML import failed - will use CPU fallback")

print("\nAfter running this cell, please restart the runtime (Runtime > Restart runtime)")
print("Then run your main code with the GPU-optimized version")

"""# Optimised Vers"""

with open('gpu_optimized_sentiment_analysis.py', 'w') as f:
    f.write("""[paste the entire GPU-optimized code here]""")

"""
Advanced Stacking Ensemble for Sentiment Analysis - GPU Optimized
This implementation leverages GPU acceleration where possible to improve performance.
"""

import numpy as np
import pandas as pd
import time
from sklearn.preprocessing import MaxAbsScaler
from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import cross_val_predict
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report
from scipy.sparse import hstack, csr_matrix

# Try importing GPU libraries, but don't crash if they're not available
GPU_AVAILABLE = False
try:
    import torch
    TORCH_GPU_AVAILABLE = torch.cuda.is_available()

    if TORCH_GPU_AVAILABLE:
        try:
            import cupy as cp
            import cudf
            from cuml import LogisticRegression as cuLogisticRegression
            from cuml.svm import LinearSVC as cuLinearSVC
            from cuml.ensemble import RandomForestClassifier as cuRandomForestClassifier
            RAPIDS_AVAILABLE = True
        except ImportError:
            RAPIDS_AVAILABLE = False

        try:
            import xgboost as xgb
            XGBOOST_GPU_AVAILABLE = True
        except ImportError:
            XGBOOST_GPU_AVAILABLE = False

        # Only consider GPU available if at least one of the libraries is available
        GPU_AVAILABLE = RAPIDS_AVAILABLE or XGBOOST_GPU_AVAILABLE
    else:
        RAPIDS_AVAILABLE = False
        XGBOOST_GPU_AVAILABLE = False
except ImportError:
    TORCH_GPU_AVAILABLE = False
    RAPIDS_AVAILABLE = False
    XGBOOST_GPU_AVAILABLE = False

# Try to import XGBoost for CPU if not already imported
if not XGBOOST_GPU_AVAILABLE:
    try:
        import xgboost as xgb
        XGBOOST_CPU_AVAILABLE = True
    except ImportError:
        XGBOOST_CPU_AVAILABLE = False
else:
    XGBOOST_CPU_AVAILABLE = XGBOOST_GPU_AVAILABLE


# Check if GPU is available
def check_gpu():
    """Check if GPU is available and print device information."""
    print("\n----- GPU Availability Check -----")

    # Check PyTorch GPU
    print(f"PyTorch: CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"PyTorch: CUDA device count: {torch.cuda.device_count()}")
        print(f"PyTorch: CUDA device name: {torch.cuda.get_device_name(0)}")

    # Check CuPy/RAPIDS
    try:
        print(f"CuPy version: {cp.__version__}")
        print(f"CuPy CUDA device: {cp.cuda.runtime.getDeviceCount()} device(s) available")
    except:
        print("CuPy not properly installed or no CUDA device available")

    # Check XGBoost
    try:
        print(f"XGBoost version: {xgb.__version__}")
        print(f"XGBoost has GPU support: {xgb.config.build_info()['USE_CUDA']}")
    except:
        print("Could not verify XGBoost GPU support")

    print("---------------------------------------\n")

# 1. Feature Engineering: Extract additional features with GPU acceleration if available

def extract_additional_features(X_data, processed_texts):
    """Extract text-based features to complement TF-IDF vectors with GPU acceleration when possible"""
    start_time = time.time()
    print("Extracting additional features...")

    try:
        # Try using GPU acceleration with cuDF
        use_gpu = torch.cuda.is_available()
        if use_gpu:
            # Convert processed_texts to a list if it's not already
            if not isinstance(processed_texts, list):
                processed_texts = processed_texts.tolist()

            # Text length
            text_lengths = [len(text) if isinstance(text, str) else 0 for text in processed_texts]

            # Word count
            word_counts = [len(text.split()) if isinstance(text, str) else 0 for text in processed_texts]

            # Average word length & Negation count
            avg_word_lengths = []
            negation_counts = []

            for text in processed_texts:
                if isinstance(text, str):
                    words = text.split()
                    if words:
                        avg_word_lengths.append(sum(len(word) for word in words) / len(words))
                        negation_counts.append(sum(1 for word in words if '_NEG' in word))
                    else:
                        avg_word_lengths.append(0)
                        negation_counts.append(0)
                else:
                    avg_word_lengths.append(0)
                    negation_counts.append(0)

            # Create DataFrame with GPU acceleration
            feature_df = cudf.DataFrame({
                'text_length': text_lengths,
                'word_count': word_counts,
                'avg_word_length': avg_word_lengths,
                'negation_count': negation_counts
            })

            # Scale features
            scaler = MaxAbsScaler()
            # Convert to CPU for scaling, then back to GPU
            cpu_features = feature_df.to_pandas()
            scaled_features = scaler.fit_transform(cpu_features)

            # Convert back to sparse matrix
            sparse_features = csr_matrix(scaled_features)

    except (ImportError, ModuleNotFoundError):
        print("GPU libraries not available, falling back to CPU processing")
        use_gpu = False

    # Fall back to CPU if GPU processing fails or isn't available
    if not use_gpu:
        # Initialize empty arrays for new features
        text_lengths = []
        word_counts = []
        avg_word_length = []
        negation_counts = []

        # Process each text entry
        for text in processed_texts:
            if isinstance(text, str):
                # Text length
                text_lengths.append(len(text))

                # Word count
                words = text.split()
                word_counts.append(len(words))

                # Average word length
                if words:
                    avg_word_length.append(sum(len(word) for word in words) / len(words))
                else:
                    avg_word_length.append(0)

                # Negation count
                negation_counts.append(sum(1 for word in words if '_NEG' in word))
            else:
                # Handle non-string entries
                text_lengths.append(0)
                word_counts.append(0)
                avg_word_length.append(0)
                negation_counts.append(0)

        # Create a DataFrame of engineered features
        feature_df = pd.DataFrame({
            'text_length': text_lengths,
            'word_count': word_counts,
            'avg_word_length': avg_word_length,
            'negation_count': negation_counts
        })

        # Scale numeric features and convert to sparse for compatibility with TF-IDF
        scaler = MaxAbsScaler()
        scaled_features = scaler.fit_transform(feature_df)
        sparse_features = csr_matrix(scaled_features)

    # Combine with TF-IDF features
    combined_features = hstack([X_data, sparse_features])

    print(f"Feature extraction completed in {time.time() - start_time:.2f} seconds")
    return combined_features

# 2. Create a stacking ensemble with meta-learning and GPU acceleration

def create_stacking_ensemble(X_train, y_train, X_val, y_val, feature_names):
    """
    Creates a stacking ensemble with multiple base models and a meta-learner,
    using GPU acceleration where possible
    """
    start_time = time.time()
    use_gpu = torch.cuda.is_available()

    # Base models with optimized hyperparameters
    base_models = {}

    # Check if we can use GPU for model training
    if use_gpu:
        try:
            print("\nTraining models with GPU acceleration...")

            # Add GPU-accelerated models
            base_models['naive_bayes'] = MultinomialNB(alpha=0.1)  # No GPU version available

            # GPU-accelerated LogisticRegression
            base_models['logistic_regression'] = cuLogisticRegression(
                C=2.0,
                penalty='l1',
                solver='saga',
                max_iter=5000
            )

            # GPU-accelerated LinearSVC
            base_models['linear_svc'] = cuLinearSVC(
                C=1.0,
                loss='squared_hinge',
                penalty='l2',
                max_iter=10000
            )

            # GPU-accelerated RandomForest
            base_models['random_forest'] = cuRandomForestClassifier(
                n_estimators=300,
                max_depth=20,
                min_samples_split=5,
                min_samples_leaf=2,
                max_features='sqrt',
                bootstrap=True,
                n_streams=4  # Parallel streams for GPU
            )

            # XGBoost with GPU acceleration
            base_models['xgboost'] = xgb.XGBClassifier(
                n_estimators=300,
                learning_rate=0.05,
                max_depth=6,
                min_child_weight=2,
                gamma=0.1,
                subsample=0.8,
                colsample_bytree=0.8,
                scale_pos_weight=1,
                reg_alpha=0.01,
                reg_lambda=1,
                use_label_encoder=False,
                tree_method='gpu_hist',  # Use GPU acceleration
                predictor='gpu_predictor',  # Use GPU for prediction
                gpu_id=0
            )

        except (ImportError, ModuleNotFoundError) as e:
            print(f"Error initializing GPU models: {e}")
            print("Falling back to CPU models")
            use_gpu = False

    # Fall back to CPU models if GPU initialization failed
    if not use_gpu:
        print("\nTraining models on CPU...")
        base_models = {
            'naive_bayes': MultinomialNB(alpha=0.1),
            'logistic_regression': LogisticRegression(
                C=2.0,
                solver='saga',
                penalty='l1',
                max_iter=5000,
                class_weight='balanced',
                n_jobs=-1,
                random_state=42
            ),
            'linear_svc': LogisticRegression(  # Replace LinearSVC with LogisticRegression
                C=1.0,
                solver='liblinear',
                penalty='l2',
                max_iter=10000,
                class_weight='balanced',
                n_jobs=-1,
                random_state=42
            ),
            'random_forest': RandomForestClassifier(
                n_estimators=300,
                max_depth=20,
                min_samples_split=5,
                min_samples_leaf=2,
                max_features='sqrt',
                bootstrap=True,
                class_weight='balanced',
                n_jobs=-1,
                random_state=42
            ),
            'xgboost': xgb.XGBClassifier(
                n_estimators=300,
                learning_rate=0.05,
                max_depth=6,
                min_child_weight=2,
                gamma=0.1,
                subsample=0.8,
                colsample_bytree=0.8,
                scale_pos_weight=1,
                reg_alpha=0.01,
                reg_lambda=1,
                use_label_encoder=False,
                eval_metric='logloss',
                n_jobs=-1,
                random_state=42
            )
        }

    # Train base models and generate meta-features
    meta_features_train = np.zeros((X_train.shape[0], len(base_models)))
    meta_features_val = np.zeros((X_val.shape[0], len(base_models)))

    print("\nTraining base models for stacking...")

    # Convert y_train and y_val to numpy arrays if they're not already
    if hasattr(y_train, 'values'):
        y_train_np = y_train.values
    else:
        y_train_np = y_train

    if hasattr(y_val, 'values'):
        y_val_np = y_val.values
    else:
        y_val_np = y_val

    for i, (name, model) in enumerate(base_models.items()):
        model_start_time = time.time()
        print(f"Training {name}...")

        # For XGBoost and cuML models, handle the sparse matrix differently
        if name == 'xgboost':
            # Convert to dense matrix for XGBoost
            if hasattr(X_train, 'toarray'):
                x_train_dense = X_train.toarray()
                x_val_dense = X_val.toarray()

                # If using GPU and more than 1GB of data, use DMatrix for better performance
                if use_gpu and (x_train_dense.nbytes > 1e9):
                    dtrain = xgb.DMatrix(x_train_dense, y_train_np)
                    dval = xgb.DMatrix(x_val_dense, y_val_np)

                    # Use native API instead of sklearn wrapper for better GPU performance
                    params = {
                        'max_depth': 6,
                        'learning_rate': 0.05,
                        'objective': 'binary:logistic',
                        'eval_metric': 'logloss',
                        'tree_method': 'gpu_hist',
                        'predictor': 'gpu_predictor',
                        'gpu_id': 0
                    }

                    # Train model
                    bst = xgb.train(
                        params,
                        dtrain,
                        num_boost_round=300
                    )

                    # Generate predictions
                    meta_features_train[:, i] = bst.predict(dtrain)
                    meta_features_val[:, i] = bst.predict(dval)
                else:
                    # Use sklearn wrapper
                    model.fit(x_train_dense, y_train_np)
                    meta_features_train[:, i] = model.predict_proba(x_train_dense)[:, 1]
                    meta_features_val[:, i] = model.predict_proba(x_val_dense)[:, 1]
            else:
                model.fit(X_train, y_train_np)
                meta_features_train[:, i] = model.predict_proba(X_train)[:, 1]
                meta_features_val[:, i] = model.predict_proba(X_val)[:, 1]

        # For RAPIDS cuML models
        elif use_gpu and name in ['logistic_regression', 'linear_svc', 'random_forest']:
            try:
                # Convert to dense for cuML
                if hasattr(X_train, 'toarray'):
                    X_train_np = X_train.toarray()
                    X_val_np = X_val.toarray()
                else:
                    X_train_np = X_train
                    X_val_np = X_val

                # Convert to CuPy arrays for GPU processing
                X_train_gpu = cp.array(X_train_np)
                y_train_gpu = cp.array(y_train_np)
                X_val_gpu = cp.array(X_val_np)

                # Fit model on GPU
                model.fit(X_train_gpu, y_train_gpu)

                # Get predictions
                if hasattr(model, 'predict_proba'):
                    proba_train = model.predict_proba(X_train_gpu)
                    proba_val = model.predict_proba(X_val_gpu)

                    # Extract probability for positive class
                    if proba_train.shape[1] > 1:  # If binary classification
                        meta_features_train[:, i] = cp.asnumpy(proba_train[:, 1])
                        meta_features_val[:, i] = cp.asnumpy(proba_val[:, 1])
                    else:  # If only one probability returned
                        meta_features_train[:, i] = cp.asnumpy(proba_train)
                        meta_features_val[:, i] = cp.asnumpy(proba_val)
                else:
                    # For models without predict_proba
                    meta_features_train[:, i] = cp.asnumpy(model.decision_function(X_train_gpu))
                    meta_features_val[:, i] = cp.asnumpy(model.decision_function(X_val_gpu))

            except Exception as e:
                print(f"Error using GPU for {name}: {e}")
                print("Falling back to CPU implementation")

                # Fall back to CPU implementation
                if name == 'logistic_regression':
                    model = LogisticRegression(C=2.0, solver='saga', penalty='l1',
                                              max_iter=5000, class_weight='balanced', n_jobs=-1)
                elif name == 'linear_svc':
                    model = LogisticRegression(C=1.0, solver='liblinear', penalty='l2',
                                              max_iter=10000, class_weight='balanced', n_jobs=-1)
                elif name == 'random_forest':
                    model = RandomForestClassifier(n_estimators=300, max_depth=20, min_samples_split=5,
                                                 min_samples_leaf=2, max_features='sqrt', n_jobs=-1)

                # Handle sparse matrices
                model.fit(X_train, y_train_np)

                if hasattr(model, 'predict_proba'):
                    meta_features_train[:, i] = model.predict_proba(X_train)[:, 1]
                    meta_features_val[:, i] = model.predict_proba(X_val)[:, 1]
                else:
                    meta_features_train[:, i] = model.decision_function(X_train)
                    meta_features_val[:, i] = model.decision_function(X_val)

        else:
            # Standard sklearn models
            if hasattr(model, 'predict_proba'):
                # Use cross_val_predict for more robust meta-features
                meta_features_train[:, i] = cross_val_predict(
                    model, X_train, y_train_np, cv=5, method='predict_proba'
                )[:, 1]

                model.fit(X_train, y_train_np)
                meta_features_val[:, i] = model.predict_proba(X_val)[:, 1]
            else:
                # For models without predict_proba
                model.fit(X_train, y_train_np)
                meta_features_train[:, i] = cross_val_predict(
                    model, X_train, y_train_np, cv=5, method='decision_function'
                )
                meta_features_val[:, i] = model.decision_function(X_val)

        print(f"  {name} trained in {time.time() - model_start_time:.2f} seconds")

    # Meta learner: Try GPU-accelerated version first, fall back to CPU if needed
    if use_gpu:
        try:
            # Convert meta-features to GPU
            meta_features_train_gpu = cp.array(meta_features_train)
            meta_features_val_gpu = cp.array(meta_features_val)
            y_train_gpu = cp.array(y_train_np)

            # Create and train GPU meta-learner
            meta_learner = cuLogisticRegression(
                C=3.0,
                penalty='l2',
                max_iter=2000
            )
            meta_learner.fit(meta_features_train_gpu, y_train_gpu)

            # Get validation predictions
            val_predictions_gpu = meta_learner.predict(meta_features_val_gpu)
            val_predictions = cp.asnumpy(val_predictions_gpu)

        except Exception as e:
            print(f"Error using GPU for meta-learner: {e}")
            print("Falling back to CPU for meta-learner")
            use_gpu = False

    # Fall back to CPU meta-learner
    if not use_gpu:
        meta_learner = LogisticRegression(
            C=3.0,
            solver='liblinear',
            max_iter=2000,
            class_weight='balanced',
            random_state=42
        )
        meta_learner.fit(meta_features_train, y_train_np)
        val_predictions = meta_learner.predict(meta_features_val)

    # Evaluate meta-learner on validation set
    val_accuracy = accuracy_score(y_val_np, val_predictions)

    print(f"\nStacking ensemble validation accuracy: {val_accuracy:.4f}")
    print("\nClassification Report (Validation):")
    print(classification_report(y_val_np, val_predictions))
    print(f"Ensemble training completed in {time.time() - start_time:.2f} seconds")

    return base_models, meta_learner, val_accuracy

# 3. Final prediction function for test data

def predict_with_stacking_ensemble(base_models, meta_learner, X_test):
    """Generate predictions using the stacking ensemble with GPU acceleration if available"""
    start_time = time.time()
    use_gpu = torch.cuda.is_available()

    # Generate meta-features for test data
    meta_features_test = np.zeros((X_test.shape[0], len(base_models)))

    for i, (name, model) in enumerate(base_models.items()):
        # For XGBoost, handle sparse matrix differently
        if name == 'xgboost':
            if hasattr(X_test, 'toarray'):
                if use_gpu and hasattr(model, 'get_booster'):  # XGBoost sklearn API with GPU
                    # Use DMatrix for faster prediction
                    dtest = xgb.DMatrix(X_test.toarray())
                    meta_features_test[:, i] = model.get_booster().predict(dtest)
                else:  # Standard prediction
                    meta_features_test[:, i] = model.predict_proba(X_test.toarray())[:, 1]
            else:
                meta_features_test[:, i] = model.predict_proba(X_test)[:, 1]

        # For RAPIDS cuML models
        elif use_gpu and name in ['logistic_regression', 'linear_svc', 'random_forest']:
            try:
                # Convert to dense for cuML
                if hasattr(X_test, 'toarray'):
                    X_test_np = X_test.toarray()
                else:
                    X_test_np = X_test

                # Convert to CuPy array for GPU processing
                X_test_gpu = cp.array(X_test_np)

                # Get predictions
                if hasattr(model, 'predict_proba'):
                    proba_test = model.predict_proba(X_test_gpu)

                    # Extract probability for positive class
                    if proba_test.shape[1] > 1:  # If binary classification
                        meta_features_test[:, i] = cp.asnumpy(proba_test[:, 1])
                    else:  # If only one probability returned
                        meta_features_test[:, i] = cp.asnumpy(proba_test)
                else:
                    # For models without predict_proba
                    meta_features_test[:, i] = cp.asnumpy(model.decision_function(X_test_gpu))

            except Exception as e:
                print(f"Error using GPU for prediction with {name}: {e}")
                # Fall back to CPU prediction
                if hasattr(X_test, 'toarray'):
                    meta_features_test[:, i] = model.predict_proba(X_test.toarray())[:, 1]
                else:
                    meta_features_test[:, i] = model.predict_proba(X_test)[:, 1]

        else:  # Standard sklearn models
            if hasattr(model, 'predict_proba'):
                meta_features_test[:, i] = model.predict_proba(X_test)[:, 1]
            else:
                meta_features_test[:, i] = model.decision_function(X_test)

    # Make final predictions with GPU acceleration if possible
    if use_gpu and not isinstance(meta_learner, LogisticRegression):  # If meta_learner is cuML
        try:
            # Convert to CuPy array
            meta_features_test_gpu = cp.array(meta_features_test)

            # Predict with GPU
            test_predictions_gpu = meta_learner.predict(meta_features_test_gpu)
            test_predictions = cp.asnumpy(test_predictions_gpu)
        except Exception as e:
            print(f"Error using GPU for meta-learner prediction: {e}")
            # Fall back to CPU
            test_predictions = meta_learner.predict(meta_features_test)
    else:
        # Standard prediction
        test_predictions = meta_learner.predict(meta_features_test)

    print(f"Prediction completed in {time.time() - start_time:.2f} seconds")
    return test_predictions

# 4. Main execution function

def improved_sentiment_analysis(X_train, y_train, X_test, y_test, X_val, y_val, processed_texts_train, processed_texts_test, processed_texts_val, feature_names):
    """
    Main function to execute the improved sentiment analysis pipeline with GPU acceleration where possible
    """
    overall_start_time = time.time()

    # Check for GPU availability
    check_gpu()

    print("Enhancing features with text metadata...")
    X_train_enhanced = extract_additional_features(X_train, processed_texts_train)
    X_val_enhanced = extract_additional_features(X_val, processed_texts_val)
    X_test_enhanced = extract_additional_features(X_test, processed_texts_test)

    print(f"Original feature shape: {X_train.shape}")
    print(f"Enhanced feature shape: {X_train_enhanced.shape}")

    # Create and train the stacking ensemble
    base_models, meta_learner, val_accuracy = create_stacking_ensemble(
        X_train_enhanced, y_train, X_val_enhanced, y_val, feature_names
    )

    # Make predictions on the test set
    test_predictions = predict_with_stacking_ensemble(
        base_models, meta_learner, X_test_enhanced
    )

    # Ensure y_test is a numpy array
    if hasattr(y_test, 'values'):
        y_test_np = y_test.values
    else:
        y_test_np = y_test

    # Evaluate performance on test set
    test_accuracy = accuracy_score(y_test_np, test_predictions)

    print("\n----- Final Test Results -----")
    print(f"Test accuracy: {test_accuracy:.4f}")
    print("\nClassification Report (Test):")
    print(classification_report(y_test_np, test_predictions))
    print(f"\nTotal execution time: {time.time() - overall_start_time:.2f} seconds")

    return test_accuracy, base_models, meta_learner

# Installation helper function
def install_required_packages():
    """
    Installs the required packages for GPU acceleration.
    This should be run in a code cell before the main script.
    """
    import sys
    import subprocess

    # Check if running in Colab
    is_colab = 'google.colab' in sys.modules

    if is_colab:
        print("Installing required packages for GPU acceleration in Google Colab...")

        # Install packages
        subprocess.check_call([sys.executable, "-m", "pip", "install", "--upgrade", "xgboost", "cupy-cuda11x", "cudf-cu11", "cuml-cu11", "torch"])

        print("\nInstallation complete. Please restart the runtime to ensure all packages are properly loaded.")
        print("After restarting, run your script to utilize GPU acceleration.")
    else:
        print("This function is designed for Google Colab. Please install packages manually in your environment.")

"""# ."""

import importlib
import gpu_optimized_sentiment_analysis
importlib.reload(gpu_optimized_sentiment_analysis)
from gpu_optimized_sentiment_analysis import improved_sentiment_analysis, check_gpu

# First check if GPU is properly configured
check_gpu()

# Then run your analysis
processed_texts_train = df.loc[y_train.index, 'processed_text']
processed_texts_val = df.loc[y_val.index, 'processed_text']
processed_texts_test = df.loc[y_test.index, 'processed_text']

test_accuracy, base_models, meta_learner = improved_sentiment_analysis(
    X_train, y_train, X_test, y_test, X_val, y_val,
    processed_texts_train, processed_texts_test, processed_texts_val,
    feature_names
)

# Run this installation cell first to set up GPU dependencies
!pip install --upgrade xgboost>=1.6.0
!pip install cupy-cuda11x
!pip install cudf-cu11 cuml-cu11 -f https://download.rapids.ai/wheels/stable/
!pip install torch

# Verify GPU access and library installation
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA device: {torch.cuda.get_device_name(0)}")

# Import required libraries for the main script
import numpy as np
import pandas as pd
import xgboost as xgb
try:
    import cupy as cp
    print("CuPy successfully imported")
except:
    print("CuPy import failed - will use CPU fallback")
try:
    import cudf
    print("cuDF successfully imported")
except:
    print("cuDF import failed - will use CPU fallback")
try:
    from cuml.svm import LinearSVC
    print("cuML successfully imported")
except:
    print("cuML import failed - will use CPU fallback")

print("\nAfter running this cell, please restart the runtime (Runtime > Restart runtime)")
print("Then run your main code with the GPU-optimized version")